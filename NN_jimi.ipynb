{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425a9c7d-6587-4b50-b26c-7f9b1d0ccb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0c37cf6-3604-400b-91c6-54d952c486ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import nibabel as nib\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8eb55a-d643-4ad3-a213-af27ecac7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908e525-51db-4c6a-bb3b-2a9eae8846a2",
   "metadata": {},
   "source": [
    "## Cuda Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad94346-0c2a-44ca-81d6-3326052c8ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avaliable:\t True\n",
      "current:\t 0\n",
      "device: \t <torch.cuda.device object at 0x00000239F25B7708>\n",
      "count:\t\t 1\n",
      "name:\t\t NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "print('avaliable:\\t', torch.cuda.is_available())\n",
    "print('current:\\t', torch.cuda.current_device())\n",
    "print('device: \\t', torch.cuda.device(0))\n",
    "print('count:\\t\\t', torch.cuda.device_count())\n",
    "print('name:\\t\\t', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72845809-bfe0-458b-94cd-c3209ad7e180",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086b01e-28a6-4c8c-964e-8ba5b358bc13",
   "metadata": {},
   "source": [
    "###### Jimi's Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc339a5-a8ca-4f99-9044-8d584799e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/BT_Classification/backup/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a68d1-e345-47ec-afa0-3d010def0786",
   "metadata": {},
   "source": [
    "## Data Augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c7e993-9d60-402e-9421-1a2a0b870926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        path: path to file\n",
    "    Return:\n",
    "        img: image tensor\n",
    "    \"\"\"\n",
    "    img_nii = nib.load(path)\n",
    "    \n",
    "    img_np = np.squeeze(img_nii.get_fdata(dtype=np.float32))\n",
    "    \n",
    "    return torch.from_numpy(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a660d09f-d190-45c3-8c74-1afc9f757e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resampled(path, size):\n",
    "    \n",
    "    pre_img = sitk.ReadImage(path)\n",
    "    # get constants \n",
    "    pre_vs = np.asarray(pre_img.GetSpacing())\n",
    "    pre_is = np.asarray(pre_img.GetSize())\n",
    "\n",
    "    # rescale post voxel spacing \n",
    "\n",
    "    post_img = sitk.Resample(\n",
    "        image1 = pre_img,\n",
    "        size = size\n",
    "    )\n",
    "    \n",
    "    img_np = sitk.GetArrayFromImage(post_img)\n",
    "    \n",
    "    return torch.from_numpy(img_np)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01beb158-2c9d-4389-b2fc-d7c1a061b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_crop_dim(full_size, crop_size):\n",
    "\n",
    "    if full_size[0] < crop_size[0] or full_size[1] < crop_size[1] or full_size[2] < crop_size[2]:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cadf3995-fd51-4c30-b5bc-e6f201ec24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_crop(image_tensor, crop_size):\n",
    "#     print(image_tensor.shape)\n",
    "    mask = np.where(image_tensor < torch.mean(image_tensor), 0, image_tensor)\n",
    "    mask[mask > 0] = 1\n",
    "#     print(mask.shape)\n",
    "    c_s, c_w, c_h = crop_size\n",
    "    f_s, f_w, f_h = image_tensor.shape\n",
    "    \n",
    "    total = np.sum(mask)\n",
    "    \n",
    "    search = True\n",
    "    while search:\n",
    "        if f_s == c_s:\n",
    "            x = 0\n",
    "        else:\n",
    "            x = np.random.randint(f_s - c_s)\n",
    "\n",
    "        if f_w == c_w:\n",
    "            y = 0\n",
    "        else:\n",
    "            y = np.random.randint(f_w - c_w)\n",
    "\n",
    "        if f_h == c_h:\n",
    "            z = 0\n",
    "        else:\n",
    "            z = np.random.randint(f_h - c_h)\n",
    "\n",
    "        cropped = mask[x:x + c_s, y:y + c_w, z:z + c_h]\n",
    "        \n",
    "        c_total = np.sum(cropped)\n",
    "        \n",
    "        if (c_total / total) > 0.1:\n",
    "            search = False\n",
    "    \n",
    "    return image_tensor[x:x + c_s, y:y + c_w, z:z + c_h]\n",
    "        \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72789cf4-fea6-4a60-9410-b1803a0b6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_crops(path, crop_size, count, label_path):\n",
    "    if type(path) == str:\n",
    "        path = [path]\n",
    "    \n",
    "    labels = pd.read_csv(label_path, dtype={'BraTS21ID':str, 'MGMT_value':np.int64})\n",
    "#     print(labels.head())\n",
    "    cropped = []\n",
    "    \n",
    "    for i, p in enumerate(path):\n",
    "        print(i, p)\n",
    "        # SKIP BECAUSE SOMETHING WRONG\n",
    "        if '00053' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        if '00186' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "            \n",
    "        # SKIP BECAUSE HOST SAID TO\n",
    "        if '00109' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        if '00123' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        if '00709' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        image_tensor = load_image(p)\n",
    "        p_id = re.split('\\\\\\\\|/', p)[-2]\n",
    "#         cropped.append([image_tensor, labels.loc[labels['BraTS21ID'] == p_id, 'MGMT_value'].iloc[0]])\n",
    "#         print(p_id)\n",
    "\n",
    "        if check_crop_dim(image_tensor.shape, crop_size):\n",
    "            print('\\tCrop size too large. Image:{} \\t crop:{}'.format(image_tensor.shape, crop_size))\n",
    "            continue\n",
    "\n",
    "        for i in range(count):\n",
    "            cropped.append([get_valid_crop(image_tensor, crop_size), labels.loc[labels['BraTS21ID'] == p_id, 'MGMT_value'].iloc[0]])\n",
    "    \n",
    "    data = torch.utils.data.DataLoader(cropped)\n",
    "    return cropped, data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2c87a4e-edbf-40ca-bbfa-8ddbc4a7d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resampled(path, size, label_path):\n",
    "    if type(path) == str:\n",
    "        path = [path]\n",
    "    \n",
    "    labels = pd.read_csv(label_path, dtype={'BraTS21ID':str, 'MGMT_value':np.int64})\n",
    "#     print(labels.head())\n",
    "    cropped = []\n",
    "    \n",
    "    for i, p in enumerate(path):\n",
    "        print(i, p)\n",
    "        # SKIP BECAUSE SOMETHING WRONG\n",
    "        if '00053' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        if '00186' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "            \n",
    "        # SKIP BECAUSE HOST SAID TO\n",
    "        if '00109' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        if '00123' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        if '00709' in p:\n",
    "            print('\\tSkipped')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        image_tensor = load_resampled(p, (100, 100, 100))\n",
    "        p_id = re.split('\\\\\\\\|/', p)[-2]\n",
    "#         cropped.append([image_tensor, labels.loc[labels['BraTS21ID'] == p_id, 'MGMT_value'].iloc[0]])\n",
    "#         print(p_id)\n",
    "\n",
    "        cropped.append([image_tensor, labels.loc[labels['BraTS21ID'] == p_id, 'MGMT_value'].iloc[0]])\n",
    "    \n",
    "    data = torch.utils.data.DataLoader(cropped)\n",
    "    return cropped, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a105e439-8455-4a5d-97fd-53081398040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 D:/BT_Classification/backup/train/00000\\FLAIR.nii\n",
      "[[tensor([[[0.1024, 0.0972, 0.1013,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0974, 0.0915, 0.1036,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0967, 0.0911, 0.1068,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0925, 0.0930, 0.0959,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0839, 0.0957, 0.1198,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0808, 0.1008, 0.1370,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0847, 0.0999, 0.1047,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0844, 0.1183, 0.1338,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0894, 0.1336, 0.1539,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         [0.0278, 0.0278, 0.0278,  ..., 0.0278, 0.0278, 0.0278],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]), 1]]\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000023A8B2A0108>\n",
      "torch.Size([1, 100, 100, 100])\n",
      "torch.Size([1, 100, 100, 100, 1])\n",
      "tensor([[[[[0.1024],\n",
      "           [0.0972],\n",
      "           [0.1013],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0974],\n",
      "           [0.0915],\n",
      "           [0.1036],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0967],\n",
      "           [0.0911],\n",
      "           [0.1068],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0925],\n",
      "           [0.0930],\n",
      "           [0.0959],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0839],\n",
      "           [0.0957],\n",
      "           [0.1198],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0808],\n",
      "           [0.1008],\n",
      "           [0.1370],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0847],\n",
      "           [0.0999],\n",
      "           [0.1047],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0844],\n",
      "           [0.1183],\n",
      "           [0.1338],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0894],\n",
      "           [0.1336],\n",
      "           [0.1539],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]]],\n",
      "\n",
      "\n",
      "         [[[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          [[0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           ...,\n",
      "           [0.0278],\n",
      "           [0.0278],\n",
      "           [0.0278]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]],\n",
      "\n",
      "          [[0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           ...,\n",
      "           [0.0000],\n",
      "           [0.0000],\n",
      "           [0.0000]]]]])\n"
     ]
    }
   ],
   "source": [
    "crops, t_data = get_resampled(path=path+'00000\\FLAIR.nii', size=(70, 70, 70), label_path=path+'/../../train_labels.csv')\n",
    "print(crops)\n",
    "print(t_data)\n",
    "\n",
    "for i, data in enumerate(t_data, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    \n",
    "    print(inputs.shape)\n",
    "    print(inputs.unsqueeze(-1).shape)\n",
    "    print(inputs.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23bc6e-182b-4d83-9afc-5bf9965d7862",
   "metadata": {},
   "source": [
    "### View Croppings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86109994-5e2f-4df7-ab20-dffeee3b3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_interactions.ipyplot as iplt\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b73c6c1-dd8e-46bd-afb3-cbde97699a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view(image):\n",
    "    def axial(ax_slice):\n",
    "        return image[ax_slice,:,:]\n",
    "\n",
    "    def cor(cor_slice):\n",
    "        return image[:,cor_slice,:]\n",
    "\n",
    "    def sag(sag_slice):\n",
    "        return image[:,:,sag_slice]\n",
    "\n",
    "    # define layout\n",
    "    fig, ax = plt.subplots(3,1)\n",
    "\n",
    "    for a in ax:\n",
    "        a.xaxis.set_visible(False)\n",
    "        a.yaxis.set_visible(False)\n",
    "\n",
    "    ctrl1 = iplt.imshow(axial, ax_slice=np.arange(image.shape[2]), aspect='auto', ax=ax[0], vmin=0, vmax=1, cmap ='gray')\n",
    "    ctrl2 = iplt.imshow(sag, sag_slice=np.arange(image.shape[0]), aspect='auto', ax=ax[1], vmin=0, vmax=1, cmap ='gray')\n",
    "    crtl3 = iplt.imshow(cor, cor_slice=np.arange(image.shape[1]), aspect='auto', ax=ax[2], vmin=0, vmax=1, cmap ='gray' )\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c71115-94bf-4ec1-b511-bfc3a15241a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c367feda2a4d47c88cd91643fd395902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32a061352c54c91b60c0eef0de6c025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='ax_slice', max=105, readout=False), Label(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3101eba9ee284b70b575c9b52dc71e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='sag_slice', max=358, readout=False), Label(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ce9706a7fc4429930b51a11180f3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='cor_slice', max=287, readout=False), Label(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(load_image(path+'00053/FLAIR.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c371a74e-b7ba-443f-bcdb-9daabd09b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c52659acc9a4d8caca17e31f99da69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b548270f1c04337bb86fc49f916ddb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='ax_slice', max=78, readout=False), Label(value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935df44a531f492b9a406655ecad9de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='sag_slice', max=262, readout=False), Label(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dc8153ceab4021a6f917fdb4868ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, description='cor_slice', max=280, readout=False), Label(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(load_image(path+'00186/FLAIR.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbfdaf7-ac74-49c6-afac-25d83da2fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(crops[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb8079-47dc-46ed-bb41-9b8755c16b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(crops[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b2b67-505c-46d2-b185-75438afe3e95",
   "metadata": {},
   "source": [
    "## Building the 3D CNN and FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ecd35da-7d20-4f31-bcca-f367a05ad7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_channel = 1\n",
    "        self.base_channel = 4\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=self.in_channel, out_channels=self.base_channel, kernel_size=3, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout3d(p=0.3),\n",
    "            nn.Conv3d(self.base_channel, self.base_channel*2, 3, bias=False),\n",
    "            nn.InstanceNorm3d(self.base_channel*2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout3d(p=0.3),\n",
    "            nn.Conv3d(self.base_channel*2, self.base_channel*4, 3, bias=False),\n",
    "            nn.InstanceNorm3d(self.base_channel*4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout3d(p=0.3),\n",
    "            nn.Conv3d(self.base_channel*4, self.base_channel*8, 3, bias=False),\n",
    "            nn.MaxPool3d(2),\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(self.base_channel*8, self.base_channel*8, 3, bias=False),\n",
    "            nn.InstanceNorm3d(self.base_channel*8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout3d(p=0.3),\n",
    "            nn.Conv3d(self.base_channel*8, self.base_channel*16, 3, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(self.base_channel*16, self.base_channel*16, 3, bias=False),\n",
    "            nn.InstanceNorm3d(self.base_channel*16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout3d(p=0.3),\n",
    "            nn.Conv3d(self.base_channel*16, self.base_channel*32, 3, bias=False),\n",
    "            nn.InstanceNorm3d(self.base_channel*32),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(628864, 64),\n",
    "#             nn.Dropout2d(p=0.2),\n",
    "#             nn.Linear(2048, 64),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.Linear(64, 8),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out2 = self.conv2(out1)\n",
    "        out3 = self.conv3(out2)\n",
    "        \n",
    "        out3 = torch.flatten(out3,1)\n",
    "        \n",
    "        out4 = self.lin(out3)\n",
    "        \n",
    "        return out4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4deed39-2e86-4b7f-b1f6-1eb078d74ec5",
   "metadata": {},
   "source": [
    "(image_w - filter_w + 2\\*padding_size) / stride+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ceb14-dfc3-4162-a237-f3e692eea66a",
   "metadata": {},
   "source": [
    "## Testing on First 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "830e06c2-ea2c-4313-90ec-5a02449a0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9af3a404-d887-4828-b90f-ba3ae963f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(path+'000**/FLAIR.nii')\n",
    "files.extend(glob.glob(path+'001**/FLAIR.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04a6fa32-7b1d-4e82-a222-8f1ee57d9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/BT_Classification/backup/train\\\\00000\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00002\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00003\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00005\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00006\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00008\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00009\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00011\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00012\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00014\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00017\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00018\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00019\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00020\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00021\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00022\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00024\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00025\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00026\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00028\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00030\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00031\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00032\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00033\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00035\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00036\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00043\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00044\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00045\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00046\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00048\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00049\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00052\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00053\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00054\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00056\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00058\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00059\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00060\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00061\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00062\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00063\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00064\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00066\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00068\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00070\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00071\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00072\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00074\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00077\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00078\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00081\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00084\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00085\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00087\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00088\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00089\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00090\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00094\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00095\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00096\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00097\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00098\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00099\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00100\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00102\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00104\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00105\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00106\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00107\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00108\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00109\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00110\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00111\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00112\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00113\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00116\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00117\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00120\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00121\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00122\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00123\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00124\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00128\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00130\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00132\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00133\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00134\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00136\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00137\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00138\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00139\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00140\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00142\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00143\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00144\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00146\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00147\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00148\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00149\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00150\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00151\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00154\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00155\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00156\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00157\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00158\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00159\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00160\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00162\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00165\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00166\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00167\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00169\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00170\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00171\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00172\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00176\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00177\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00178\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00183\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00184\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00185\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00186\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00187\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00188\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00191\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00192\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00193\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00194\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00195\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00196\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00197\\\\FLAIR.nii', 'D:/BT_Classification/backup/train\\\\00199\\\\FLAIR.nii']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99f164e5-f6d2-4bdd-a251-5dfffb3c674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 D:/BT_Classification/backup/train\\00000\\FLAIR.nii\n",
      "1 D:/BT_Classification/backup/train\\00002\\FLAIR.nii\n",
      "2 D:/BT_Classification/backup/train\\00003\\FLAIR.nii\n",
      "3 D:/BT_Classification/backup/train\\00005\\FLAIR.nii\n",
      "4 D:/BT_Classification/backup/train\\00006\\FLAIR.nii\n",
      "5 D:/BT_Classification/backup/train\\00008\\FLAIR.nii\n",
      "6 D:/BT_Classification/backup/train\\00009\\FLAIR.nii\n",
      "7 D:/BT_Classification/backup/train\\00011\\FLAIR.nii\n",
      "8 D:/BT_Classification/backup/train\\00012\\FLAIR.nii\n",
      "9 D:/BT_Classification/backup/train\\00014\\FLAIR.nii\n",
      "10 D:/BT_Classification/backup/train\\00017\\FLAIR.nii\n",
      "11 D:/BT_Classification/backup/train\\00018\\FLAIR.nii\n",
      "12 D:/BT_Classification/backup/train\\00019\\FLAIR.nii\n",
      "13 D:/BT_Classification/backup/train\\00020\\FLAIR.nii\n",
      "14 D:/BT_Classification/backup/train\\00021\\FLAIR.nii\n",
      "15 D:/BT_Classification/backup/train\\00022\\FLAIR.nii\n",
      "16 D:/BT_Classification/backup/train\\00024\\FLAIR.nii\n",
      "17 D:/BT_Classification/backup/train\\00025\\FLAIR.nii\n",
      "18 D:/BT_Classification/backup/train\\00026\\FLAIR.nii\n",
      "19 D:/BT_Classification/backup/train\\00028\\FLAIR.nii\n",
      "20 D:/BT_Classification/backup/train\\00030\\FLAIR.nii\n",
      "21 D:/BT_Classification/backup/train\\00031\\FLAIR.nii\n",
      "22 D:/BT_Classification/backup/train\\00032\\FLAIR.nii\n",
      "23 D:/BT_Classification/backup/train\\00033\\FLAIR.nii\n",
      "24 D:/BT_Classification/backup/train\\00035\\FLAIR.nii\n",
      "25 D:/BT_Classification/backup/train\\00036\\FLAIR.nii\n",
      "26 D:/BT_Classification/backup/train\\00043\\FLAIR.nii\n",
      "27 D:/BT_Classification/backup/train\\00044\\FLAIR.nii\n",
      "28 D:/BT_Classification/backup/train\\00045\\FLAIR.nii\n",
      "29 D:/BT_Classification/backup/train\\00046\\FLAIR.nii\n",
      "30 D:/BT_Classification/backup/train\\00048\\FLAIR.nii\n",
      "31 D:/BT_Classification/backup/train\\00049\\FLAIR.nii\n",
      "32 D:/BT_Classification/backup/train\\00052\\FLAIR.nii\n",
      "33 D:/BT_Classification/backup/train\\00053\\FLAIR.nii\n",
      "\tSkipped\n",
      "34 D:/BT_Classification/backup/train\\00054\\FLAIR.nii\n",
      "35 D:/BT_Classification/backup/train\\00056\\FLAIR.nii\n",
      "36 D:/BT_Classification/backup/train\\00058\\FLAIR.nii\n",
      "37 D:/BT_Classification/backup/train\\00059\\FLAIR.nii\n",
      "38 D:/BT_Classification/backup/train\\00060\\FLAIR.nii\n",
      "39 D:/BT_Classification/backup/train\\00061\\FLAIR.nii\n",
      "40 D:/BT_Classification/backup/train\\00062\\FLAIR.nii\n",
      "41 D:/BT_Classification/backup/train\\00063\\FLAIR.nii\n",
      "42 D:/BT_Classification/backup/train\\00064\\FLAIR.nii\n",
      "43 D:/BT_Classification/backup/train\\00066\\FLAIR.nii\n",
      "44 D:/BT_Classification/backup/train\\00068\\FLAIR.nii\n",
      "45 D:/BT_Classification/backup/train\\00070\\FLAIR.nii\n",
      "46 D:/BT_Classification/backup/train\\00071\\FLAIR.nii\n",
      "47 D:/BT_Classification/backup/train\\00072\\FLAIR.nii\n",
      "48 D:/BT_Classification/backup/train\\00074\\FLAIR.nii\n",
      "49 D:/BT_Classification/backup/train\\00077\\FLAIR.nii\n",
      "50 D:/BT_Classification/backup/train\\00078\\FLAIR.nii\n",
      "51 D:/BT_Classification/backup/train\\00081\\FLAIR.nii\n",
      "52 D:/BT_Classification/backup/train\\00084\\FLAIR.nii\n",
      "53 D:/BT_Classification/backup/train\\00085\\FLAIR.nii\n",
      "54 D:/BT_Classification/backup/train\\00087\\FLAIR.nii\n",
      "55 D:/BT_Classification/backup/train\\00088\\FLAIR.nii\n",
      "56 D:/BT_Classification/backup/train\\00089\\FLAIR.nii\n",
      "57 D:/BT_Classification/backup/train\\00090\\FLAIR.nii\n",
      "58 D:/BT_Classification/backup/train\\00094\\FLAIR.nii\n",
      "59 D:/BT_Classification/backup/train\\00095\\FLAIR.nii\n",
      "60 D:/BT_Classification/backup/train\\00096\\FLAIR.nii\n",
      "61 D:/BT_Classification/backup/train\\00097\\FLAIR.nii\n",
      "62 D:/BT_Classification/backup/train\\00098\\FLAIR.nii\n",
      "63 D:/BT_Classification/backup/train\\00099\\FLAIR.nii\n",
      "64 D:/BT_Classification/backup/train\\00100\\FLAIR.nii\n",
      "65 D:/BT_Classification/backup/train\\00102\\FLAIR.nii\n",
      "66 D:/BT_Classification/backup/train\\00104\\FLAIR.nii\n",
      "67 D:/BT_Classification/backup/train\\00105\\FLAIR.nii\n",
      "68 D:/BT_Classification/backup/train\\00106\\FLAIR.nii\n",
      "69 D:/BT_Classification/backup/train\\00107\\FLAIR.nii\n",
      "70 D:/BT_Classification/backup/train\\00108\\FLAIR.nii\n",
      "71 D:/BT_Classification/backup/train\\00109\\FLAIR.nii\n",
      "\tSkipped\n",
      "72 D:/BT_Classification/backup/train\\00110\\FLAIR.nii\n",
      "73 D:/BT_Classification/backup/train\\00111\\FLAIR.nii\n",
      "74 D:/BT_Classification/backup/train\\00112\\FLAIR.nii\n",
      "75 D:/BT_Classification/backup/train\\00113\\FLAIR.nii\n",
      "76 D:/BT_Classification/backup/train\\00116\\FLAIR.nii\n",
      "77 D:/BT_Classification/backup/train\\00117\\FLAIR.nii\n",
      "78 D:/BT_Classification/backup/train\\00120\\FLAIR.nii\n",
      "79 D:/BT_Classification/backup/train\\00121\\FLAIR.nii\n",
      "80 D:/BT_Classification/backup/train\\00122\\FLAIR.nii\n",
      "81 D:/BT_Classification/backup/train\\00123\\FLAIR.nii\n",
      "\tSkipped\n",
      "82 D:/BT_Classification/backup/train\\00124\\FLAIR.nii\n",
      "83 D:/BT_Classification/backup/train\\00128\\FLAIR.nii\n",
      "84 D:/BT_Classification/backup/train\\00130\\FLAIR.nii\n",
      "85 D:/BT_Classification/backup/train\\00132\\FLAIR.nii\n",
      "86 D:/BT_Classification/backup/train\\00133\\FLAIR.nii\n",
      "87 D:/BT_Classification/backup/train\\00134\\FLAIR.nii\n",
      "88 D:/BT_Classification/backup/train\\00136\\FLAIR.nii\n",
      "89 D:/BT_Classification/backup/train\\00137\\FLAIR.nii\n",
      "90 D:/BT_Classification/backup/train\\00138\\FLAIR.nii\n",
      "91 D:/BT_Classification/backup/train\\00139\\FLAIR.nii\n",
      "92 D:/BT_Classification/backup/train\\00140\\FLAIR.nii\n",
      "93 D:/BT_Classification/backup/train\\00142\\FLAIR.nii\n",
      "94 D:/BT_Classification/backup/train\\00143\\FLAIR.nii\n",
      "95 D:/BT_Classification/backup/train\\00144\\FLAIR.nii\n",
      "96 D:/BT_Classification/backup/train\\00146\\FLAIR.nii\n",
      "97 D:/BT_Classification/backup/train\\00147\\FLAIR.nii\n",
      "98 D:/BT_Classification/backup/train\\00148\\FLAIR.nii\n",
      "99 D:/BT_Classification/backup/train\\00149\\FLAIR.nii\n",
      "100 D:/BT_Classification/backup/train\\00150\\FLAIR.nii\n",
      "101 D:/BT_Classification/backup/train\\00151\\FLAIR.nii\n",
      "102 D:/BT_Classification/backup/train\\00154\\FLAIR.nii\n",
      "103 D:/BT_Classification/backup/train\\00155\\FLAIR.nii\n",
      "104 D:/BT_Classification/backup/train\\00156\\FLAIR.nii\n",
      "105 D:/BT_Classification/backup/train\\00157\\FLAIR.nii\n",
      "106 D:/BT_Classification/backup/train\\00158\\FLAIR.nii\n",
      "107 D:/BT_Classification/backup/train\\00159\\FLAIR.nii\n",
      "108 D:/BT_Classification/backup/train\\00160\\FLAIR.nii\n",
      "109 D:/BT_Classification/backup/train\\00162\\FLAIR.nii\n",
      "110 D:/BT_Classification/backup/train\\00165\\FLAIR.nii\n",
      "111 D:/BT_Classification/backup/train\\00166\\FLAIR.nii\n",
      "112 D:/BT_Classification/backup/train\\00167\\FLAIR.nii\n",
      "113 D:/BT_Classification/backup/train\\00169\\FLAIR.nii\n",
      "114 D:/BT_Classification/backup/train\\00170\\FLAIR.nii\n",
      "115 D:/BT_Classification/backup/train\\00171\\FLAIR.nii\n",
      "116 D:/BT_Classification/backup/train\\00172\\FLAIR.nii\n",
      "117 D:/BT_Classification/backup/train\\00176\\FLAIR.nii\n",
      "118 D:/BT_Classification/backup/train\\00177\\FLAIR.nii\n",
      "119 D:/BT_Classification/backup/train\\00178\\FLAIR.nii\n",
      "120 D:/BT_Classification/backup/train\\00183\\FLAIR.nii\n",
      "121 D:/BT_Classification/backup/train\\00184\\FLAIR.nii\n",
      "122 D:/BT_Classification/backup/train\\00185\\FLAIR.nii\n",
      "123 D:/BT_Classification/backup/train\\00186\\FLAIR.nii\n",
      "\tSkipped\n",
      "124 D:/BT_Classification/backup/train\\00187\\FLAIR.nii\n",
      "125 D:/BT_Classification/backup/train\\00188\\FLAIR.nii\n",
      "126 D:/BT_Classification/backup/train\\00191\\FLAIR.nii\n",
      "127 D:/BT_Classification/backup/train\\00192\\FLAIR.nii\n",
      "128 D:/BT_Classification/backup/train\\00193\\FLAIR.nii\n",
      "129 D:/BT_Classification/backup/train\\00194\\FLAIR.nii\n",
      "130 D:/BT_Classification/backup/train\\00195\\FLAIR.nii\n",
      "131 D:/BT_Classification/backup/train\\00196\\FLAIR.nii\n",
      "132 D:/BT_Classification/backup/train\\00197\\FLAIR.nii\n",
      "133 D:/BT_Classification/backup/train\\00199\\FLAIR.nii\n"
     ]
    }
   ],
   "source": [
    "crops, train_data = get_resampled(files, size=(100, 100, 100), label_path=path+'/../../train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0d21cc9-3805-4122-a51b-be90fd6da0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "print(len(crops))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "419df9f4-a417-4ba8-95e3-cfc144582c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a310cdd-47ea-4080-92dc-0822f4a64510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbc59e31-2905-4104-8f02-8aa746b30e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e6c53e2d-b1b4-4dee-bf18-4d9bd8b29507",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-6c68d6aa8368>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m-> 1121\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2824\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\" \n",
    "else:\n",
    "    dev = 'cpu'\n",
    "\n",
    "# net.to('cpu')\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(train_data, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.unsqueeze(1))\n",
    "        loss = criterion(outputs, labels.unsqueeze(0).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print('[%d] loss: %.3f' %\n",
    "              (epoch + 1, loss.item()))\n",
    "        \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        }, path+'/../../checkpoints/cp_{}.cp'.format(epoch))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(), path+'/../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3c65a-ed5b-4ba0-b8d0-073031b3e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
